{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiV22fXuq99VA9wmLqTdNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eternalHopeWithAI/e2eML/blob/basic_analysis_and_visualisation/dataset_analysis_and_visualisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality Reduction\n",
        "\n",
        "Merge several correlated features into one. Also known as Feature Extraction.\n",
        "With lesser dimension, the choosen algorithm learns faster and in some cases performance also improves."
      ],
      "metadata": {
        "id": "S2-YNz074GUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenges of ML**\n",
        "\n",
        "\n",
        "*   Bad Algorithm\n",
        "*   Bad Data\n",
        "\n",
        "--> It has been proven in various studies that data matters more than the algorithm for complex problems.\n",
        "\n",
        "**Nonrepresentative Training Data**\n",
        "Training data should be representative of the new cases you want to generalise to. ex: the set of countries in the 'gdp' vs 'life satisfaction' analysis using linear models was not perfecttly representative; a few counties were missing. It is crucial to use a training set that is representative of the cases you want to generalise to.\n",
        "\n",
        "**2 reasons**\n",
        "If the sample is too small, you will have sampling noise i.e. nonrepresentative data as a result of chance.\n",
        "Very large samples can may as well be nonrepresentative if the sampling method is flawed. this is called as sampling bias.\n",
        "\n",
        "**Poor Quality Data**\n",
        "If your training data is full of errors, outliers, and noise. the pattern would be difficult to uncover.\n",
        "\n",
        "examples:\n",
        "1. If some instances are clearly outliers, then simply discard them or fix the error.\n",
        "2. Some datapoints missing.\n",
        "\n",
        "**Irrelevant Features**\n",
        "** Feature Engineering **\n",
        "Feature Selection\n",
        "Selecting the most useful features to train on among existing features.\n",
        "\n",
        "Feature Extraction\n",
        "combining the existing features to produce a more useful one - using dimensionality reduction algorithms.\n",
        "\n",
        "Creating new features by gathering new data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bfq1KnXI55l1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVm4VcmI5CcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}